#!/usr/bin/env python3
"""
Toolify å‡½æ•°è°ƒç”¨æµ‹è¯•è„šæœ¬
æµ‹è¯• claude-sonnet-4-20250514 æ¨¡å‹çš„å·¥å…·è°ƒç”¨èƒ½åŠ›
"""

import json
from openai import OpenAI

# è¿æ¥åˆ° Toolify ä¸­é—´ä»¶
client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="65187777"  # é…ç½®æ–‡ä»¶ä¸­çš„ allowed_keys
)

# å®šä¹‰æµ‹è¯•å·¥å…·ï¼šè·å–å¤©æ°”ä¿¡æ¯
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å½“å‰å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€æ·±åœ³"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "æ¸©åº¦å•ä½"
                    }
                },
                "required": ["city"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "calculate",
            "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "è¦è®¡ç®—çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ï¼š2+2ã€10*5"
                    }
                },
                "required": ["expression"]
            }
        }
    }
]

def test_single_tool_call():
    """æµ‹è¯•å•ä¸ªå·¥å…·è°ƒç”¨"""
    print("\n" + "="*60)
    print("æµ‹è¯• 1: å•ä¸ªå·¥å…·è°ƒç”¨ - æŸ¥è¯¢å¤©æ°”")
    print("="*60)
    
    response = client.chat.completions.create(
        model="claude-sonnet-4-20250514",
        messages=[
            {"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}
        ],
        tools=tools,
        temperature=0.7
    )
    
    print(f"\nğŸ“ æ¨¡å‹: {response.model}")
    print(f"ğŸ¯ å®ŒæˆåŸå› : {response.choices[0].finish_reason}")
    
    if response.choices[0].message.tool_calls:
        print(f"ğŸ”§ å·¥å…·è°ƒç”¨æ•°é‡: {len(response.choices[0].message.tool_calls)}")
        for i, tool_call in enumerate(response.choices[0].message.tool_calls, 1):
            print(f"\n  å·¥å…· #{i}:")
            print(f"    - ID: {tool_call.id}")
            print(f"    - åç§°: {tool_call.function.name}")
            print(f"    - å‚æ•°: {tool_call.function.arguments}")
    else:
        print(f"ğŸ’¬ å›å¤: {response.choices[0].message.content}")
    
    print(f"\nğŸ“Š Token ä½¿ç”¨:")
    print(f"    - è¾“å…¥: {response.usage.prompt_tokens}")
    print(f"    - è¾“å‡º: {response.usage.completion_tokens}")
    print(f"    - æ€»è®¡: {response.usage.total_tokens}")

def test_multiple_tool_calls():
    """æµ‹è¯•å¤šä¸ªå·¥å…·è°ƒç”¨"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: å¤šä¸ªå·¥å…·è°ƒç”¨ - å¤©æ°”æŸ¥è¯¢ + è®¡ç®—")
    print("="*60)
    
    response = client.chat.completions.create(
        model="claude-sonnet-4-20250514",
        messages=[
            {"role": "user", "content": "å¸®æˆ‘æŸ¥ä¸€ä¸‹åŒ—äº¬å’Œä¸Šæµ·çš„å¤©æ°”ï¼Œç„¶åè®¡ç®— 25 + 37 ç­‰äºå¤šå°‘"}
        ],
        tools=tools,
        temperature=0.7
    )
    
    print(f"\nğŸ“ æ¨¡å‹: {response.model}")
    print(f"ğŸ¯ å®ŒæˆåŸå› : {response.choices[0].finish_reason}")
    
    if response.choices[0].message.tool_calls:
        print(f"ğŸ”§ å·¥å…·è°ƒç”¨æ•°é‡: {len(response.choices[0].message.tool_calls)}")
        for i, tool_call in enumerate(response.choices[0].message.tool_calls, 1):
            print(f"\n  å·¥å…· #{i}:")
            print(f"    - ID: {tool_call.id}")
            print(f"    - åç§°: {tool_call.function.name}")
            print(f"    - å‚æ•°: {tool_call.function.arguments}")
    else:
        print(f"ğŸ’¬ å›å¤: {response.choices[0].message.content}")
    
    print(f"\nğŸ“Š Token ä½¿ç”¨:")
    print(f"    - è¾“å…¥: {response.usage.prompt_tokens}")
    print(f"    - è¾“å‡º: {response.usage.completion_tokens}")
    print(f"    - æ€»è®¡: {response.usage.total_tokens}")

def test_no_tool_needed():
    """æµ‹è¯•ä¸éœ€è¦å·¥å…·çš„æ™®é€šå¯¹è¯"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: æ™®é€šå¯¹è¯ - ä¸éœ€è¦å·¥å…·")
    print("="*60)
    
    response = client.chat.completions.create(
        model="claude-sonnet-4-20250514",
        messages=[
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
        ],
        tools=tools,
        temperature=0.7
    )
    
    print(f"\nğŸ“ æ¨¡å‹: {response.model}")
    print(f"ğŸ¯ å®ŒæˆåŸå› : {response.choices[0].finish_reason}")
    
    if response.choices[0].message.tool_calls:
        print(f"ğŸ”§ å·¥å…·è°ƒç”¨æ•°é‡: {len(response.choices[0].message.tool_calls)}")
    else:
        print(f"ğŸ’¬ å›å¤: {response.choices[0].message.content}")
    
    print(f"\nğŸ“Š Token ä½¿ç”¨:")
    print(f"    - è¾“å…¥: {response.usage.prompt_tokens}")
    print(f"    - è¾“å‡º: {response.usage.completion_tokens}")
    print(f"    - æ€»è®¡: {response.usage.total_tokens}")

def test_streaming():
    """æµ‹è¯•æµå¼å“åº”"""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: æµå¼å“åº” - å·¥å…·è°ƒç”¨")
    print("="*60)
    
    stream = client.chat.completions.create(
        model="claude-sonnet-4-20250514",
        messages=[
            {"role": "user", "content": "æ·±åœ³ç°åœ¨å¤©æ°”å¦‚ä½•ï¼Ÿ"}
        ],
        tools=tools,
        stream=True,
        temperature=0.7
    )
    
    print("\nğŸ“¡ æµå¼è¾“å‡º:")
    tool_calls_detected = False
    
    for chunk in stream:
        if chunk.choices and len(chunk.choices) > 0:
            delta = chunk.choices[0].delta
            
            if hasattr(delta, 'tool_calls') and delta.tool_calls:
                if not tool_calls_detected:
                    print("\nğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨!")
                    tool_calls_detected = True
                
                for tool_call in delta.tool_calls:
                    if hasattr(tool_call, 'function') and tool_call.function:
                        if hasattr(tool_call.function, 'name') and tool_call.function.name:
                            print(f"  - å·¥å…·: {tool_call.function.name}")
                        if hasattr(tool_call.function, 'arguments') and tool_call.function.arguments:
                            print(f"  - å‚æ•°ç‰‡æ®µ: {tool_call.function.arguments}", end='')
            
            elif hasattr(delta, 'content') and delta.content:
                print(delta.content, end='', flush=True)
            
            if chunk.choices[0].finish_reason:
                print(f"\n\nğŸ¯ å®ŒæˆåŸå› : {chunk.choices[0].finish_reason}")

if __name__ == "__main__":
    print("\n" + "ğŸš€"*30)
    print("Toolify å‡½æ•°è°ƒç”¨åŠŸèƒ½æµ‹è¯•")
    print("æµ‹è¯•æ¨¡å‹: claude-sonnet-4-20250514")
    print("ğŸš€"*30)
    
    try:
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        test_single_tool_call()
        test_multiple_tool_calls()
        test_no_tool_needed()
        test_streaming()
        
        print("\n" + "âœ…"*30)
        print("æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("âœ…"*30 + "\n")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

